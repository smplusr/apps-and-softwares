{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gnc-chat-agent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8burlIaTrE0Z"
      },
      "source": [
        "# Install and resolve dependencies\n",
        "\n",
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6X7QONxrMBU"
      },
      "source": [
        "# Import AI model from gpt-neo\n",
        "\n",
        "print(\"Available models:\\n\")\n",
        "print(\"     -> gpt-neo-2.7B\")\n",
        "print(\"     -> gpt-neo-1.3B\")\n",
        "print(\"     -> gpt-neo-350M\")\n",
        "print(\"     -> gpt-neo-125M\")\n",
        "print(\"\")\n",
        "\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "\n",
        "intern_input = input()\n",
        "model = GPTNeoForCausalLM.from_pretrained(f'EleutherAI/{intern_input}')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(f'EleutherAI/{intern_input}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53rU7eJqlEf7"
      },
      "source": [
        "# GPT-Neo Chatbot Agent   (GNC-Agent) ~ Uncommented\n",
        "\n",
        "class GNC_Agent:\n",
        "  def __init__(self, max_length, gen_full_sentences, file):\n",
        "      self.max_length = max_length\n",
        "      self.gen_full_sentences = gen_full_sentences\n",
        "      self.gen_text = \"\"\n",
        "      self.memory = \"\"\n",
        "      if file: self.ReadMemory(file)\n",
        "\n",
        "  def CutString(self, string, chars):\n",
        "    i = 0\n",
        "    for c in string:\n",
        "      i += 1\n",
        "      for s in chars:\n",
        "        if c == s:\n",
        "          return string[:i]\n",
        "    return string\n",
        "\n",
        "  def ReadMemory(self, file):\n",
        "    self.memory = \"\"\n",
        "    with open(file, 'r') as content:\n",
        "      self.memory += content.read()\n",
        "      content.close()\n",
        "\n",
        "  def WriteMemory(self, file):\n",
        "    with open(file, 'w') as content:\n",
        "      content.write(self.memory)\n",
        "      content.close()\n",
        "\n",
        "  def Guard(self, prompt):\n",
        "    if prompt != \"\" and prompt[0] == ',':\n",
        "      prompt = prompt.replace(',', 'self.')\n",
        "      eval(prompt)\n",
        "      return True\n",
        "\n",
        "  def Undo(self):\n",
        "    self.memory = self.memory.replace(self.gen_text, \"\")\n",
        "    self.gen_text = \"\"\n",
        "\n",
        "  def Generate(self, prompt):\n",
        "    if self.Guard(prompt) == True: return True, True\n",
        "    self.memory += prompt\n",
        "\n",
        "    while 1:\n",
        "      input_ids = tokenizer(self.memory, return_tensors=\"pt\").input_ids\n",
        "      gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=len(input_ids[0])+ self.max_length, pad_token_id=50256)\n",
        "      self.gen_text = self.CutString(tokenizer.batch_decode(gen_tokens)[0].replace(tokenizer.batch_decode(input_ids)[0], ''), '.?!')     # WARN: case sensitive: self.memory !tokenized\n",
        "      if self.gen_text != tokenizer.batch_decode(gen_tokens)[0].replace(tokenizer.batch_decode(input_ids)[0], '') or not self.gen_full_sentences:\n",
        "        break\n",
        "        \n",
        "    self.memory += self.gen_text\n",
        "    return self.gen_text, self.memory\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRidGIwTSUyz"
      },
      "source": [
        "agent = GNC_Agent(16, False, False)  # Agent instantiation with base max length set as 16 chars, full sentences generation on (sentences will end with either '.', '?' or '!'), and load file disabled.\n",
        "\n",
        "while 1:\n",
        "  print(agent.Generate(input())[0])  # Printing the first returned member of method GNC_Agent.Generate(). Member is gen_text"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
