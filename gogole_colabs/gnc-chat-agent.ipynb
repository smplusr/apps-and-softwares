{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gnc-chat-agent.ipynb","provenance":[{"file_id":"https://github.com/smplusr/apps-and-sofwares/blob/main/google-colabs/gnc-chat-agent.ipynb","timestamp":1636700974179},{"file_id":"1OLQyazNJN5wyvm0CnCPN9vYFMZqEGTrF","timestamp":1636700166927},{"file_id":"https://github.com/smplusr/apps-and-sofwares/blob/main/google-colabs/gnc-chat-agent.ipynb","timestamp":1636699884352}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"8burlIaTrE0Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0dbfb110-bf91-4176-c830-f9ee74d25acc"},"source":["# Install and resolve dependencies\n","\n","!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install transformers"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.8.1+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n","\u001b[K     |█████████████▌                  | 834.1 MB 1.4 MB/s eta 0:14:04tcmalloc: large alloc 1147494400 bytes == 0x558c86888000 @  0x7fef8b700615 0x558c4df624cc 0x558c4e04247a 0x558c4df652ed 0x558c4e056e1d 0x558c4dfd8e99 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd8d00 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4e057c66 0x558c4dfd4daf 0x558c4e057c66 0x558c4dfd4daf 0x558c4e057c66 0x558c4dfd4daf 0x558c4df67039 0x558c4dfaa409 0x558c4df65c52 0x558c4dfd8c25 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4915 0x558c4df66afa 0x558c4dfd4c0d 0x558c4dfd39ee\n","\u001b[K     |█████████████████               | 1055.7 MB 1.4 MB/s eta 0:11:03tcmalloc: large alloc 1434370048 bytes == 0x558ccaede000 @  0x7fef8b700615 0x558c4df624cc 0x558c4e04247a 0x558c4df652ed 0x558c4e056e1d 0x558c4dfd8e99 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd8d00 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4e057c66 0x558c4dfd4daf 0x558c4e057c66 0x558c4dfd4daf 0x558c4e057c66 0x558c4dfd4daf 0x558c4df67039 0x558c4dfaa409 0x558c4df65c52 0x558c4dfd8c25 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4915 0x558c4df66afa 0x558c4dfd4c0d 0x558c4dfd39ee\n","\u001b[K     |█████████████████████▋          | 1336.2 MB 1.2 MB/s eta 0:08:38tcmalloc: large alloc 1792966656 bytes == 0x558c4fd10000 @  0x7fef8b700615 0x558c4df624cc 0x558c4e04247a 0x558c4df652ed 0x558c4e056e1d 0x558c4dfd8e99 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd8d00 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4e057c66 0x558c4dfd4daf 0x558c4e057c66 0x558c4dfd4daf 0x558c4e057c66 0x558c4dfd4daf 0x558c4df67039 0x558c4dfaa409 0x558c4df65c52 0x558c4dfd8c25 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4915 0x558c4df66afa 0x558c4dfd4c0d 0x558c4dfd39ee\n","\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:04:08tcmalloc: large alloc 2241208320 bytes == 0x558cbaaf8000 @  0x7fef8b700615 0x558c4df624cc 0x558c4e04247a 0x558c4df652ed 0x558c4e056e1d 0x558c4dfd8e99 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd8d00 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4e057c66 0x558c4dfd4daf 0x558c4e057c66 0x558c4dfd4daf 0x558c4e057c66 0x558c4dfd4daf 0x558c4df67039 0x558c4dfaa409 0x558c4df65c52 0x558c4dfd8c25 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4915 0x558c4df66afa 0x558c4dfd4c0d 0x558c4dfd39ee\n","\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x558d4045a000 @  0x7fef8b6ff1e7 0x558c4df98067 0x558c4df624cc 0x558c4e04247a 0x558c4df652ed 0x558c4e056e1d 0x558c4dfd8e99 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4df66afa 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4dfd39ee\n","tcmalloc: large alloc 2477727744 bytes == 0x558e2ab78000 @  0x7fef8b700615 0x558c4df624cc 0x558c4e04247a 0x558c4df652ed 0x558c4e056e1d 0x558c4dfd8e99 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd4c0d 0x558c4df66afa 0x558c4dfd4c0d 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4dfd39ee 0x558c4df66bda 0x558c4dfd5737 0x558c4dfd39ee 0x558c4df67271\n","\u001b[K     |████████████████████████████████| 1982.2 MB 1.3 kB/s \n","\u001b[?25hCollecting torchvision==0.9.1+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n","\u001b[K     |████████████████████████████████| 17.6 MB 52 kB/s \n","\u001b[?25hCollecting torchaudio===0.8.1\n","  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 11.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.10.0.2)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n"]}]},{"cell_type":"code","metadata":{"id":"y6X7QONxrMBU"},"source":["# Import AI model from gpt-neo\n","\n","print(\"Available models:\\n\")\n","print(\"     -> gpt-neo-2.7B\")\n","print(\"     -> gpt-neo-1.3B\")\n","print(\"     -> gpt-neo-350M\")\n","print(\"     -> gpt-neo-125M\")\n","print(\"\")\n","\n","from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n","\n","intern_input = input()\n","model = GPTNeoForCausalLM.from_pretrained(f'EleutherAI/{intern_input}')\n","tokenizer = GPT2Tokenizer.from_pretrained(f'EleutherAI/{intern_input}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53rU7eJqlEf7"},"source":["# GPT-Neo Chatbot Agent   (GNC-Agent) ~ Uncommented\n","\n","class GNC_Agent:\n","  def __init__(self, max_length, gen_full_sentences, file):\n","      self.max_length = max_length\n","      self.gen_full_sentences = gen_full_sentences\n","      self.memory = \"\"\n","      if file: self.ReadMemory(file)\n","\n","  def CutString(self, string, chars):\n","    i = 0\n","    for c in string:\n","      i += 1\n","      for s in chars:\n","        if c == s:\n","          return string[:i]\n","    return string\n","\n","  def ReadMemory(self, file):\n","    self.memory = \"\"\n","    with open(file, 'r') as content:\n","      self.memory += content.read()\n","      content.close()\n","\n","  def WriteMemory(self, file):\n","    with open(file, 'w') as content:\n","      content.write(self.memory)\n","      content.close()\n","\n","  def Guard(self, prompt):\n","    if prompt != \"\":\n","      if prompt[0] == ',':\n","        prompt=prompt.replace(',', 'self.')\n","        eval(prompt)\n","        return True\n","\n","  def Undo(self):\n","    self.memory = self.memory.replace(self.gen_text, \"\")\n","    self.gen_text = \"\"\n","\n","  def Generate(self, prompt):\n","    if self.Guard(prompt) == True: return\n","    self.memory += prompt\n","\n","    while 1:\n","      input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n","      gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=self.max_length, pad_token_id=50256)\n","      gen_text = self.CutString(tokenizer.batch_decode(gen_tokens)[0].replace(prompt, ''), '.?!')\n","      if gen_text != tokenizer.batch_decode(gen_tokens)[0].replace(prompt, '') or not self.gen_full_sentences:\n","        break\n","\n","    self.memory += gen_text\n","    return gen_text, self.memory\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yRidGIwTSUyz"},"source":["agent = GNC_Agent(16, True, False)  # Agent instantiation with base max length set as 16 chars, full sentences generation on (sentences will end with either '.', '?' or '!'), and load file disabled.\n","\n","print(agent.Generate(input())[0])  # Printing the first returned member of method GNC_Agent.Generate(). Member is gen_text"],"execution_count":null,"outputs":[]}]}
