{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-neo_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ_I_Wat6id9"
      },
      "source": [
        "This Utility is the Google Colab version of the one available here:\n",
        "  - https://github.com/smplusr\n",
        "\n",
        "This tool contains 3 mains parts:\n",
        "  - The install mechanism, written in BASH\n",
        "  - The model setup script, written in Python\n",
        "  - The actual agent, also written in Python\n",
        "\n",
        "You only need to run the installer the first time you launch the software.\n",
        "After that, dependancies will be resolved.\n",
        "\n",
        "The python scripts will need to be ran in python3. The setup needs to be launched BEFORE the chatbot agent. Once that is done, you can run the agent script.\n",
        "\n",
        "BE CAREFUL, you might have to do these steps again as soon as you close you python console. Downloads will still persist but the pipeline importation and generation will require to be executed again.\n",
        "\n",
        "also, GPT-NEO, as one of the most powerful pretrained transformer model that synthetize high quality human native language REQUIRES A REALLY POWERFUL HOST.\n",
        "The 1.3B version requires at least 11GB of RAM, barely running inside Google Colab free sessions and the 2.7B needing more that 16GB !\n",
        "CPU and GPU are also really important ! Without some good hardware, simple text generation might take A LOT of time to be completed and it may even crash or damage hardware ! BE CAREFUL !\n",
        "\n",
        "the GNC-Agent, or GPT-Neo Chatbot Agent is aimed to run on very little function calls. The class comes with 7 prebuild functions, including the init constructor function. List of functions in the source code.\n",
        "\n",
        "Here is a example of functions that can be ran in a python3 GPT session.\n",
        "\n",
        "  - agent = GNC_Agent(15)\n",
        " \n",
        "  - agent.Generate(input())\n",
        "\n",
        "  - print(f\"{agent.result}\")\n",
        "  - print(f\"{agent.memory}\")\n",
        "  \n",
        "  - agent.Guard(\",max_length = 30\")\n",
        "  - agent.Undo()\n",
        "\n",
        "  - agent.ReadMemory(\"file.txt\")\n",
        "  - agent.WriteMemory(\"file.txt\")\n",
        "\n",
        "The result member of the agent will be the most recent string formated output of the AI. This result can be undone leading to one undo possible on the actual agent's memory. This memory will be built on all the inputs from the user and the AI, leading to actual conversations or context simulation.\n",
        "\n",
        "There is a built-in debug / sandbox mode allowing to call the agent's inner function from the input prompt. In order to use it, just write a comma: ',' as the first character of a paragraph, then you can unter a method and event parameters. Those are cumulable ! (Example: \",WriteMemory(\"file.txt\") ,Undo()\")\n",
        "\n",
        "Of course, the most important function, from which the debug inputs can be entered is: the Generate method. Though, the Guard (debug method) can be accessed directly.\n",
        "\n",
        "\n",
        " -> Huge thanks to EleutherAI and their amazing work on GPT-Neo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8burlIaTrE0Z"
      },
      "source": [
        "# Install and resolve dependencies\n",
        "\n",
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6X7QONxrMBU"
      },
      "source": [
        "# Import AI model from gpt-neo\n",
        "\n",
        "print(\"Available models:  \")\n",
        "print(\"     -> gpt-neo-2.7B\")\n",
        "print(\"     -> gpt-neo-1.3B\")\n",
        "print(\"     -> gpt-neo-350M\")\n",
        "print(\"     -> gpt-neo-125M\")\n",
        "print(\"\")\n",
        "from transformers import pipelines\n",
        "\n",
        "model = input(\"please choose a model: \")\n",
        "generate = pipelines.pipeline('text-generation', model=f'EleutherAI/{model}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53rU7eJqlEf7"
      },
      "source": [
        "# GPT-Neo Chatbot Agent   (GNC-Agent) ~ Uncommented\n",
        "\n",
        "class GNC_Agent:\n",
        "    def __init__(self, length):\n",
        "      self.result = \"\"\n",
        "      self.memory = \"\"\n",
        "      self.length = 0\n",
        "      self.max_length = length\n",
        "\n",
        "    def CountWords(self, input):\n",
        "      self.length = 0\n",
        "      word_list = input.split()\n",
        "      for i in word_list:\n",
        "        self.length += 1\n",
        "      return self.length\n",
        "\n",
        "    def Generate(self, input):\n",
        "      if self.Guard(input) == True: return\n",
        "\n",
        "      self.memory += input\n",
        "      self.CountWords(self.memory)\n",
        "      \n",
        "      res = generate(self.memory, max_length = self.length + self.max_length, do_sample = True, temperature = 0.9, pad_token_id = 50256)\n",
        "      self.result = res[0][\"generated_text\"]\n",
        "      \n",
        "      self.result = self.result.replace(self.memory, \"\")\n",
        "      self.result = self.result.replace(input, \"\")\n",
        "      self.result = self.result.replace(\"\\n\", \"\")\n",
        "      \n",
        "      self.memory += self.result\n",
        "      return self.result, self.memory\n",
        "\n",
        "    def Guard(self, input):\n",
        "      if input[0] == ',':\n",
        "        input = input.replace(',', 'self.')\n",
        "        eval(input)\n",
        "        return True\n",
        "\n",
        "    def ReadMemory (self, file):\n",
        "      self.memory = \"\"\n",
        "      with open(file, 'r') as content:\n",
        "        self.memory += content.read()\n",
        "        content.close()\n",
        "\n",
        "    def WriteMemory(self, file):\n",
        "      with open(file, 'w') as content:\n",
        "        content.write(self.memory)\n",
        "        content.close()\n",
        "\n",
        "    def Undo(self):\n",
        "      self.memory = self.memory.replace(self.result, \"\")      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDeW9jH0_KFl"
      },
      "source": [
        "agent = GNC_Agent(15)       # Agent instantiation with base max length set as 15 char.\n",
        "\n",
        "while(1):\n",
        " \n",
        "  agent.Generate(input())   # Here, Inputs will be retrived from the user and sent to the Generate agent's method.\n",
        "  print(f\"{agent.result}\")  # And here, the \"result\" member of the agent will be printed."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}